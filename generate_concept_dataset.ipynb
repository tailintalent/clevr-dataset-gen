{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c122fb2a-33c3-4edb-bc22-d2bc6aab0104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import json\n",
    "import numpy as np\n",
    "import imageio\n",
    "from numbers import Number\n",
    "import pdb\n",
    "import random\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import sys, os\n",
    "sys.path.append(os.path.join(os.path.dirname(\"__file__\"), '..'))\n",
    "sys.path.append(os.path.join(os.path.dirname(\"__file__\"), '..', '..'))\n",
    "from reasoning.pytorch_net.util import Dictionary, first_item, to_cpu_recur, try_call, Printer, transform_dict, MineDataset, is_diagnose, reduce_tensor, get_hashing, pdump, pload, remove_elements, loss_op_core, filter_kwargs, to_Variable, gather_broadcast, get_pdict, COLOR_LIST, set_seed, Zip, Early_Stopping, init_args, make_dir, str2bool, get_filename_short, get_machine_name, get_device, record_data, plot_matrices, filter_filename, get_next_available_key, to_np_array, to_Variable, get_filename_short, write_to_config, Dictionary, Batch, to_cpu\n",
    "from reasoning.util import color_dict, clip_grad, identity_fun, seperate_concept, to_one_hot, onehot_to_RGB, get_root_dir, get_module_parameters, assign_embedding_value, get_hashing, to_device_recur, visualize_matrices, repeat_n, mask_iou_score, shrink, get_obj_from_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa149140-36a8-4315-92c3-ac0f95e15a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask_filename(image_filaname, image_filenames, include_aio=False):\n",
    "    string = image_filename.split(\".png\")[0]\n",
    "    if include_aio:\n",
    "        return [filename for filename in image_filenames if \"mask\" in filename and string in filename]\n",
    "    else:\n",
    "        return [filename for filename in image_filenames if \"mask\" in filename and string in filename and not \"aio\" in filename]\n",
    "\n",
    "def get_image(dirname, image_filename, resize=None, is_square=True, antialias=False):\n",
    "    img = torch.FloatTensor(imageio.imread(dirname + \"images/\" + image_filename).transpose(2,0,1)[:3]/255)\n",
    "    if is_square:\n",
    "        img = img[...,40:-40]\n",
    "    if resize is None:\n",
    "        return img\n",
    "    else:\n",
    "        return F.interpolate(img[None], size=resize, mode='bilinear' if antialias else \"nearest\", antialias=antialias)[0]\n",
    "\n",
    "def get_mask(mask_raw):\n",
    "    return ((mask_raw - 64/255) > 1e-5).any(0)[None].float()\n",
    "\n",
    "def get_image_and_mask(\n",
    "    chosen_filename,\n",
    "    obj_id,\n",
    "    n_objs,\n",
    "    dirname,\n",
    "    image_filenames,\n",
    "    resize=None,\n",
    "    is_square=True,\n",
    "    isplot=False,\n",
    "    check_square_oob=\"None\",\n",
    "):\n",
    "    if not isinstance(obj_id, list) and not isinstance(obj_id, tuple):\n",
    "        obj_id = [obj_id]\n",
    "    img = get_image(dirname, chosen_filename+\".png\", resize=resize, is_square=is_square, antialias=True)\n",
    "    if isplot:\n",
    "        visualize_matrices([img], use_color_dict=False)\n",
    "    masks = []\n",
    "    is_valid = True\n",
    "    if check_square_oob != \"None\":\n",
    "        assert check_square_oob == \"all\"\n",
    "        mask_list = []\n",
    "        for id in range(n_objs):\n",
    "            mask_filename = chosen_filename + f\"_mask_{id}.png\"\n",
    "            mask_raw = get_image(dirname, mask_filename, resize=None, is_square=False, antialias=False)\n",
    "            mask = get_mask(mask_raw)\n",
    "            if (mask[..., :40] > 0).any() or (mask[..., -40:] > 0).any():\n",
    "                is_valid = False\n",
    "                break\n",
    "            # processing:\n",
    "            if is_square:\n",
    "                mask_raw = mask_raw[...,40:-40]\n",
    "            if resize is not None:\n",
    "                mask_raw = F.interpolate(mask_raw[None], size=resize, mode=\"nearest\", antialias=False)[0]\n",
    "            mask = get_mask(mask_raw)\n",
    "            mask_list.append(mask)\n",
    "\n",
    "    if is_valid:\n",
    "        masks = [mask_list[id] for id in obj_id]\n",
    "        if isplot:\n",
    "            plot_matrices([ele[0] for ele in masks], images_per_row=6)\n",
    "    else:\n",
    "        img, masks, mask_list = None, None, None\n",
    "    return img, masks, mask_list\n",
    "\n",
    "\n",
    "def get_all_relations(objects):\n",
    "    Dict = {\"SameColor\": \"color\", \"SameShape\": \"shape\", \"SameSize\": \"size\"}\n",
    "    relations = []\n",
    "    for i, obj1 in enumerate(objects):\n",
    "        for j, obj2 in enumerate(objects):\n",
    "            if i < j:\n",
    "                for relation in [\"SameColor\", \"SameShape\", \"SameSize\"]:\n",
    "                    key = Dict[relation]\n",
    "                    if obj1[key] == obj2[key]:\n",
    "                        relations.append((i, j, relation))\n",
    "    return relations\n",
    "\n",
    "\n",
    "def get_clevr_concept_data_core(filter_dict, dirname, resize=(60,60), n_examples=None, image_filenames=None, isplot=False):\n",
    "    assert len(filter_dict) == 1\n",
    "    concept = get_cap(first_item(filter_dict))\n",
    "    json_filenames = sorted(filter_filename(dirname + \"scenes\"))\n",
    "    chosen_filenames = []\n",
    "    data_list = []\n",
    "    for k, json_filename in enumerate(json_filenames):\n",
    "        meta = json.load(open(dirname + \"scenes/\" + json_filename))\n",
    "        objects = meta[\"objects\"]\n",
    "        objs_valid_list = []\n",
    "        for i, obj in enumerate(objects):\n",
    "            is_chosen = True\n",
    "            for key, value in filter_dict.items():\n",
    "                if obj[key] != value:\n",
    "                    is_chosen = False\n",
    "                    break\n",
    "            if is_chosen:\n",
    "                objs_valid_list.append(i)\n",
    "        if len(objs_valid_list) > 0:\n",
    "            if isplot:\n",
    "                print(f\"{k}:\")\n",
    "            chosen_filename = json_filename.split(\".json\")[0]\n",
    "            obj_id = np.random.choice(objs_valid_list)\n",
    "            img, masks, mask_list = get_image_and_mask(\n",
    "                chosen_filename, obj_id, \n",
    "                n_objs=len(objects),\n",
    "                dirname=dirname,\n",
    "                image_filenames=image_filenames,\n",
    "                resize=resize,\n",
    "                check_square_oob=\"all\",\n",
    "                isplot=isplot,\n",
    "            )\n",
    "            if masks is None:\n",
    "                continue\n",
    "            chosen_filenames.append((chosen_filename, obj_id))\n",
    "            obj_spec = get_obj_spec(objects)\n",
    "            node_id_map = OrderedDict({\n",
    "                f\"obj_{i}\": i for i in range(len(mask_list))\n",
    "            })\n",
    "            id_object_mask = OrderedDict({i: mask_ele for i, mask_ele in enumerate(mask_list)})\n",
    "            info = Dictionary({\n",
    "                \"dirname\": dirname,\n",
    "                \"chosen_filename\": chosen_filename,\n",
    "                \"obj_id\": obj_id,\n",
    "                \"meta\": meta,\n",
    "                \"obj_spec\": obj_spec,\n",
    "                \"node_id_map\": node_id_map,\n",
    "                \"id_object_mask\": id_object_mask,\n",
    "            })\n",
    "            if isplot:\n",
    "                print(obj_spec)\n",
    "                plot_matrices([ele[0] for ele in mask_list], images_per_row=6)\n",
    "            data = (\n",
    "                img,\n",
    "                tuple(masks),\n",
    "                concept,\n",
    "                info,\n",
    "            )\n",
    "            data_list.append(data)\n",
    "            if len(data_list) % 100 == 0 or len(data_list) == n_examples:\n",
    "                print(len(data_list))\n",
    "        if n_examples is not None and len(data_list) >= n_examples:\n",
    "            break\n",
    "    return data_list\n",
    "\n",
    "\n",
    "def get_clevr_relation_data_core(relation, dirname, resize=(64,64), n_examples=None, image_filenames=None, isplot=False):\n",
    "    json_filenames = sorted(filter_filename(dirname + \"scenes\"))\n",
    "    chosen_filenames = []\n",
    "    data_list = []\n",
    "    Dict = {\"SameColor\": \"color\", \"SameShape\": \"shape\", \"SameSize\": \"size\"}\n",
    "    for k, json_filename in enumerate(json_filenames):\n",
    "        meta = json.load(open(dirname + \"scenes/\" + json_filename))\n",
    "        objects = meta[\"objects\"]\n",
    "        pairs = []\n",
    "        for i, obj1 in enumerate(objects):\n",
    "            for j, obj2 in enumerate(objects):\n",
    "                if i < j:\n",
    "                    key = Dict[relation]\n",
    "                    if obj1[key] == obj2[key]:\n",
    "                        pairs.append((i, j))\n",
    "        if len(pairs) > 0:\n",
    "            if isplot:\n",
    "                print(f\"{k}:\")\n",
    "            chosen_filename = json_filename.split(\".json\")[0]\n",
    "            obj_ids = pairs[np.random.choice(len(pairs))]\n",
    "            img, masks, mask_list = get_image_and_mask(\n",
    "                chosen_filename,\n",
    "                obj_ids, \n",
    "                n_objs=len(objects),\n",
    "                dirname=dirname,\n",
    "                image_filenames=image_filenames,\n",
    "                resize=resize,\n",
    "                check_square_oob=\"all\",\n",
    "                isplot=isplot,\n",
    "            )\n",
    "            if masks is None:\n",
    "                continue\n",
    "            chosen_filenames.append((chosen_filename, obj_ids))\n",
    "            obj_spec = get_obj_spec(objects)\n",
    "            node_id_map = OrderedDict({\n",
    "                f\"obj_{i}\": i for i in range(len(mask_list))\n",
    "            })\n",
    "            id_object_mask = OrderedDict({i: mask_ele for i, mask_ele in enumerate(mask_list)})\n",
    "            relations = get_all_relations(objects)\n",
    "            info = Dictionary({\n",
    "                \"dirname\": dirname,\n",
    "                \"chosen_filename\": chosen_filename,\n",
    "                \"obj_id\": obj_ids,\n",
    "                \"meta\": meta,\n",
    "                \"obj_spec\": obj_spec,\n",
    "                \"node_id_map\": node_id_map,\n",
    "                \"id_object_mask\": id_object_mask,\n",
    "                \"relations\": relations,\n",
    "            })\n",
    "            if isplot:\n",
    "                print(obj_spec)\n",
    "                plot_matrices([ele[0] for ele in mask_list], images_per_row=6)\n",
    "            data = (\n",
    "                img,\n",
    "                tuple(masks),\n",
    "                relation,\n",
    "                info,\n",
    "            )\n",
    "            data_list.append(data)\n",
    "            if len(data_list) % 100 == 0 or len(data_list) == n_examples:\n",
    "                print(len(data_list))\n",
    "        if n_examples is not None and len(data_list) >= n_examples:\n",
    "            break\n",
    "    return data_list\n",
    "\n",
    "\n",
    "def get_clevr_concept_data(mode, canvas_size=(64,64), n_examples=None, dirname=None, isplot=False):\n",
    "    if isinstance(canvas_size, Number):\n",
    "        canvas_size = (canvas_size, canvas_size)\n",
    "    modes = mode.split(\"+\")\n",
    "    n_examples_ele = int(np.ceil(n_examples / len(modes)))\n",
    "    data_list_all = []\n",
    "    if dirname is None:\n",
    "        dirname = \"/dfs/user/tailin/.results/CLEVR_relation/clevr-concept-relation-v2-mpi-0-60000/\"\n",
    "    image_filenames = sorted(filter_filename(dirname + \"images\"))\n",
    "    for mode_ele in modes:\n",
    "        print(f\"mode: {mode_ele}:\")\n",
    "        filter_dict = {MAP_DICT[mode_ele][0]: MAP_DICT[mode_ele][1]}\n",
    "        data_list = get_clevr_concept_data_core(\n",
    "            filter_dict,\n",
    "            dirname,\n",
    "            resize=canvas_size,\n",
    "            n_examples=n_examples_ele,\n",
    "            image_filenames=image_filenames,\n",
    "            isplot=isplot,\n",
    "        )\n",
    "        data_list_all += data_list\n",
    "    data_list_all = data_list_all[:n_examples]\n",
    "    random.shuffle(data_list_all)\n",
    "    return data_list_all\n",
    "\n",
    "\n",
    "def get_clevr_relation_data(mode, canvas_size=(64,64), n_examples=None, dirname=None, isplot=False):\n",
    "    if isinstance(canvas_size, Number):\n",
    "        canvas_size = (canvas_size, canvas_size)\n",
    "    modes = mode.split(\"+\")\n",
    "    n_examples_ele = int(np.ceil(n_examples / len(modes)))\n",
    "    data_list_all = []\n",
    "    if dirname is None:\n",
    "        dirname = \"/dfs/user/tailin/.results/CLEVR_relation/clevr-concept-relation-v2-mpi-0-60000/\"\n",
    "    image_filenames = sorted(filter_filename(dirname + \"images\"))\n",
    "    for relation in modes:\n",
    "        print(f\"mode: {relation}:\")\n",
    "        data_list = get_clevr_relation_data_core(\n",
    "            relation,\n",
    "            dirname,\n",
    "            resize=canvas_size,\n",
    "            n_examples=n_examples_ele,\n",
    "            image_filenames=image_filenames,\n",
    "            isplot=isplot,\n",
    "        )\n",
    "        data_list_all += data_list\n",
    "    data_list_all = data_list_all[:n_examples]\n",
    "    random.shuffle(data_list_all)\n",
    "    return data_list_all\n",
    "\n",
    "\n",
    "def get_cap(string):\n",
    "    return string[0].upper() + string[1:]\n",
    "\n",
    "\n",
    "def get_obj_spec(objects):\n",
    "    obj_spec = []\n",
    "    for i, obj in enumerate(objects):\n",
    "        types = f'{get_cap(obj[\"color\"])}+{get_cap(obj[\"shape\"])}+{get_cap(obj[\"size\"])}+{get_cap(obj[\"material\"])}'\n",
    "        obj_spec_ele = [(f\"obj_{i}\", f\"{types}_[-1]\"), \"Attr\"]\n",
    "        obj_spec.append(obj_spec_ele)\n",
    "    return obj_spec\n",
    "\n",
    "\n",
    "MAP_DICT = {\n",
    "    \"Red\": (\"color\", \"red\"),\n",
    "    \"Green\": (\"color\", \"green\"),\n",
    "    \"Blue\": (\"color\", \"blue\"),\n",
    "    \"Cube\": (\"shape\", \"cube\"),\n",
    "    \"Cylinder\": (\"shape\", \"cylinder\"),\n",
    "    \"Large\": (\"size\", \"large\"),\n",
    "    \"Small\": (\"size\", \"small\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05299b7-4fcf-4ea1-8742-9b6765a83a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     mode = \"Red+Green+Blue+Cube+Cylinder+Large+Small\"\n",
    "#     dirname = \"/dfs/user/tailin/.results/CLEVR_relation/clevr-concept-relation-v2-mpi-0-60000/\"\n",
    "#     data_list = get_clevr_concept_data(mode, canvas_size=(64,64), n_examples=440, dirname=dirname)\n",
    "#     pdump(data_list, \"/dfs/user/tailin/.results/CLEVR_relation/clevr-concept-relation-saved/\" + f\"data_list_canvas_{64}_ex_{20000}_1.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5660338-b69f-49c6-8202-42f44dd39288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter_dict = {\"color\": \"red\"}\n",
    "# dirname = \"/dfs/user/tailin/.results/CLEVR_relation/clevr-concept-relation-v2-mpi-0-60000/\"\n",
    "# resize=(60,60)\n",
    "# n_examples=100\n",
    "# image_filenames = sorted(filter_filename(dirname + \"images\"))\n",
    "# isplot=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ef4ab0-59b8-414f-8a65-e0a4a12b5885",
   "metadata": {},
   "source": [
    "### Relation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25edf3e-679e-4095-be66-38199d1ea4a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    mode = \"SameColor+SameShape+SameSize\"\n",
    "    dirname = \"/dfs/user/tailin/.results/CLEVR_relation/clevr-concept-relation-v2-mpi-0-60000/\"\n",
    "    data_list = get_clevr_relation_data(mode, canvas_size=(32,32), n_examples=25000, dirname=dirname, isplot=True)\n",
    "    pdump(data_list, \"/dfs/user/tailin/.results/CLEVR_relation/clevr-concept-relation-saved/\" + f\"data_list_canvas_relation_{32}_ex_{25000}_1.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3bdbb4-2773-4b77-a7db-db61ef4287aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ce3fc7-97fd-4518-a679-595c8b4a36b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    mode = \"SameColor+SameShape+SameSize\"\n",
    "    dirname = \"/dfs/user/tailin/.results/CLEVR_relation/clevr-concept-relation-v2-mpi-0-60000/\"\n",
    "    data_list = get_clevr_relation_data(mode, canvas_size=(64,64), n_examples=25000, dirname=dirname)\n",
    "    pdump(data_list, \"/dfs/user/tailin/.results/CLEVR_relation/clevr-concept-relation-saved/\" + f\"data_list_canvas_relation_{64}_ex_{25000}_1.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211f257d-e4e4-491e-8d25-cd772cc9a006",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    mode = \"SameColor+SameShape+SameSize\"\n",
    "    dirname = \"/dfs/user/tailin/.results/CLEVR_relation/clevr-concept-relation-v2-mpi-60000-130000/\"\n",
    "    data_list = get_clevr_relation_data(mode, canvas_size=(64,64), n_examples=30000, dirname=dirname)\n",
    "    pdump(data_list, \"/dfs/user/tailin/.results/CLEVR_relation/clevr-concept-relation-saved/\" + f\"data_list_canvas_relation_{64}_ex_{30000}_2.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3459df-98b5-4d08-8b32-fcb7c3bbdccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    mode = \"SameColor+SameShape+SameSize\"\n",
    "    dirname = \"/dfs/user/tailin/.results/CLEVR_relation/clevr-concept-relation-v2-mpi-130000-150000/\"\n",
    "    data_list = get_clevr_relation_data(mode, canvas_size=(64,64), n_examples=11000, dirname=dirname)\n",
    "    pdump(data_list, \"/dfs/user/tailin/.results/CLEVR_relation/clevr-concept-relation-saved/\" + f\"data_list_canvas_relation_{64}_ex_{11000}_3.p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4980e08-ec9d-4344-9859-68cf03e28745",
   "metadata": {},
   "source": [
    "### Concept:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8ebc64-b9bc-4982-bad9-a02193c58bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    mode = \"SameColor+SameShape+SameSize\"\n",
    "    dirname = \"/dfs/user/tailin/.results/CLEVR_relation/clevr-concept-relation-v2-mpi-0-60000/\"\n",
    "    data_list = get_clevr_relation_data(mode, canvas_size=(64,64), n_examples=440, dirname=dirname)\n",
    "    pdump(data_list, \"/dfs/user/tailin/.results/CLEVR_relation/clevr-concept-relation-saved/\" + f\"data_list_canvas_relation_{64}_ex_{440}.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ef8c30-036d-4cc0-ba98-39cb220f96f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    mode = \"SameColor+SameShape+SameSize\"\n",
    "    dirname = \"/dfs/user/tailin/.results/CLEVR_relation/clevr-concept-relation-v2-mpi-0-60000/\"\n",
    "    data_list = get_clevr_concept_data(mode, canvas_size=(64,64), n_examples=25000, dirname=dirname)\n",
    "    pdump(data_list, \"/dfs/user/tailin/.results/CLEVR_relation/clevr-concept-relation-saved/\" + f\"data_list_canvas_{64}_ex_{25000}_1.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dce729-2465-49e8-8120-1d41bfc015c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    mode = \"Red+Green+Blue+Cube+Cylinder+Large+Small\"\n",
    "    dirname = \"/dfs/user/tailin/.results/CLEVR_relation/clevr-concept-relation-v2-mpi-0-60000/\"\n",
    "    data_list = get_clevr_concept_data(mode, canvas_size=(64,64), n_examples=25000, dirname=dirname)\n",
    "    pdump(data_list, \"/dfs/user/tailin/.results/CLEVR_relation/clevr-concept-relation-saved/\" + f\"data_list_canvas_{64}_ex_{25000}_1.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d240666-e8b0-4a0f-b830-3ae67316c352",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    mode = \"Red+Green+Blue+Cube+Cylinder+Large+Small\"\n",
    "    dirname = \"/dfs/user/tailin/.results/CLEVR_relation/clevr-concept-relation-v2-mpi-60000-130000/\"\n",
    "    data_list = get_clevr_concept_data(mode, canvas_size=(64,64), n_examples=25000, dirname=dirname)\n",
    "    pdump(data_list, \"/dfs/user/tailin/.results/CLEVR_relation/clevr-concept-relation-saved/\" + f\"data_list_canvas_{64}_ex_{25000}_2.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ca63ee-8aa2-4f82-a045-7434ef08716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    mode = \"Red+Green+Blue+Cube+Cylinder+Large+Small\"\n",
    "    dirname = \"/dfs/user/tailin/.results/CLEVR_relation/clevr-concept-relation-v2-mpi-130000-150000/\"\n",
    "    data_list = get_clevr_concept_data(mode, canvas_size=(64,64), n_examples=5000, dirname=dirname)\n",
    "    pdump(data_list, \"/dfs/user/tailin/.results/CLEVR_relation/clevr-concept-relation-saved/\" + f\"data_list_canvas_{64}_ex_{5000}_3.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defe202b-87b3-412e-afe5-bcc6e27983da",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    isplot = True\n",
    "    dirname = \"/dfs/user/tailin/.results/CLEVR_relation/clevr-concept-relation-v2-mpi-0-60000/\"\n",
    "    json_filenames = sorted(filter_filename(dirname + \"scenes\"))\n",
    "    image_filenames = sorted(filter_filename(dirname + \"images\"))\n",
    "    filter_dict = {\n",
    "        \"color\": \"red\",  # \"red\", \"green\", \"blue\",\n",
    "        # \"shape\": \"cube\", # \"cube\", \"cylinder\"\n",
    "        # \"size\": \"big\",   # \"big\", \"small\"\n",
    "    }\n",
    "    data_list = get_clevr_concept_data_core(filter_dict, dirname, resize=(64,64), n_examples=100, isplot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a076c80-ac02-44a8-a9f3-4a453bce05d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Steps:\n",
    "1. Able to load image, mask and corresponding json property (10min)\n",
    "2. Write a function that given any concept, prepare concept dataset (1h)\n",
    "3. Write a function that given any relation, prepare relation dataset (0.5h)\n",
    "4. Training concept dataset, begin by testing overfitting (1h)\n",
    "5. Train relation dataset, begin by overfitting (0.5h)\n",
    "6. Validation dataset\n",
    "7. Baseline\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baset3",
   "language": "python",
   "name": "baset3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
